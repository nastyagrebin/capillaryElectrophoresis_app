{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b729c64-75dc-423a-a481-be8e64ba89b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Notebook cell: build time from scalar sampling + run length, read ALL ordinate_values\n",
    "\n",
    "from __future__ import annotations\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _open_cdf(path: str):\n",
    "    \"\"\"Return (dataset_handle, backend).\"\"\"\n",
    "    try:\n",
    "        import netCDF4\n",
    "        return netCDF4.Dataset(path, \"r\"), \"netcdf4\"\n",
    "    except Exception:\n",
    "        import xarray as xr\n",
    "        # Prefer scipy (no cftime); fallback to netcdf4\n",
    "        try:\n",
    "            return xr.open_dataset(path, engine=\"scipy\", decode_times=False), \"xarray\"\n",
    "        except Exception:\n",
    "            return xr.open_dataset(path, engine=\"netcdf4\", decode_times=False), \"xarray\"\n",
    "\n",
    "def _get_var(ds, name: str):\n",
    "    return ds.variables[name] if hasattr(ds, \"variables\") else ds[name]\n",
    "\n",
    "def _as_float_scalar(obj) -> float:\n",
    "    # Works for netCDF4 Variable 0-d, xarray DataArray 0-d, numpy scalar\n",
    "    if hasattr(obj, \"values\"):\n",
    "        arr = np.asarray(obj.values)\n",
    "    else:\n",
    "        arr = np.asarray(obj[:]) if hasattr(obj, \"__getitem__\") else np.asarray(obj)\n",
    "    return float(arr.reshape(()))\n",
    "\n",
    "def convert_cdf_scalar_timing_to_csv(\n",
    "    path: str,\n",
    "    out: str | None = None,\n",
    "    *,\n",
    "    prefer_minutes: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads:\n",
    "      - ordinate_values: 1D intensities (length N)\n",
    "      - actual_sampling_interval (seconds): dt\n",
    "      - actual_run_time_length (seconds): T\n",
    "      - actual_delay_time (seconds, optional): t0 (defaults 0)\n",
    "    Constructs time: t = t0 + dt * arange(N_expected), with robust fallback to len(y).\n",
    "    Writes CSV if `out` is provided. Returns DataFrame(time,intensity).\n",
    "    \"\"\"\n",
    "    path = str(path)\n",
    "    if not pathlib.Path(path).exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    ds, backend = _open_cdf(path)\n",
    "    try:\n",
    "        names = list(ds.variables.keys()) if hasattr(ds, \"variables\") else list(ds.variables)\n",
    "        if \"ordinate_values\" not in names:\n",
    "            raise ValueError(\"CDF missing 'ordinate_values' (intensity) array.\")\n",
    "\n",
    "        # Read FULL intensity vector (no preview)\n",
    "        var_y = _get_var(ds, \"ordinate_values\")\n",
    "        y = np.asarray(var_y.values if hasattr(var_y, \"values\") else var_y[:], dtype=float)\n",
    "\n",
    "        # Required scalar timing\n",
    "        if \"actual_sampling_interval\" not in names or \"actual_run_time_length\" not in names:\n",
    "            raise ValueError(\"CDF must contain 'actual_sampling_interval' and 'actual_run_time_length' scalars.\")\n",
    "        dt  = _as_float_scalar(_get_var(ds, \"actual_sampling_interval\"))\n",
    "        T   = _as_float_scalar(_get_var(ds, \"actual_run_time_length\"))\n",
    "        t0  = _as_float_scalar(_get_var(ds, \"actual_delay_time\")) if \"actual_delay_time\" in names else 0.0\n",
    "\n",
    "        # Expected length from header\n",
    "        N_expected = int(round(T / dt)) + 1  # e.g., 1200.25/0.25 â†’ 4801\n",
    "        if y.size == N_expected:\n",
    "            t = t0 + dt * np.arange(N_expected, dtype=float)\n",
    "        else:\n",
    "            # Vendor rounding quirks: trust the actual data length\n",
    "            t = t0 + dt * np.arange(y.size, dtype=float)\n",
    "\n",
    "        if prefer_minutes:\n",
    "            t = t / 60.0\n",
    "\n",
    "        # Clean finite & align lengths (defensive)\n",
    "        n = min(t.size, y.size)\n",
    "        t, y = t[:n], y[:n]\n",
    "        mask = np.isfinite(t) & np.isfinite(y)\n",
    "        t, y = t[mask], y[mask]\n",
    "\n",
    "        df = pd.DataFrame({\"time\": t, \"intensity\": y})\n",
    "        if out:\n",
    "            out_path = out if str(out).lower().endswith(\".csv\") else str(pathlib.Path(out).with_suffix(\".csv\"))\n",
    "            df.to_csv(out_path, index=False)\n",
    "        return df\n",
    "    finally:\n",
    "        try:\n",
    "            ds.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba1a978c-8999-493c-a8da-44e69de3ba8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4801, 2),\n",
       "    time  intensity\n",
       " 0  0.00    0.02019\n",
       " 1  0.25    0.02023\n",
       " 2  0.50    0.02128\n",
       " 3  0.75    0.02238\n",
       " 4  1.00    0.02198)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "df = convert_cdf_scalar_timing_to_csv(\"1AM_1.cdf\", out=\"1AM_1.csv\", prefer_minutes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ea5cb-6535-4ad7-9a01-bd3068a54d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
